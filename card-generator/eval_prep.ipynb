{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries/modules\n",
    "import gensim\n",
    "import cardgen as cg\n",
    "import gs_probdist as gspd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained embeddings\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the probability distribution.\n",
    "goldstd_data = gspd.read_in_categorised()\n",
    "category_prob_dist = gspd.freq_dist_to_prob_dist(goldstd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_many_cards(list_of_mws, prob_dist, model):\n",
    "    \"\"\"\n",
    "    Calls card_generator() for every main word in the input list.\n",
    "    \n",
    "    Args:\n",
    "        list_of_mws: a list of strings, each representing a main word to generate.\n",
    "        prob_dist: probability distribution of categories, output of freq_dist_to_prob_dist()\n",
    "        model: gensim word2vec embeddings model\n",
    "    Returns:\n",
    "        A dictionary where each key is a MW and each dictionary is a list of TWs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise new dictionary to collect the cards as we generate them.\n",
    "    card_dict = dict()\n",
    "    \n",
    "    # Go through all MWs in the input list, getting their card and adding it to the dictionary.\n",
    "    for mw in list_of_mws:\n",
    "        card = cg.card_generator(mw, prob_dist, model)\n",
    "        card_dict[mw] = card[mw]\n",
    "        \n",
    "    return card_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cake': ['cover', 'pastry', 'frosting', 'dessert', 'brownie'],\n",
       " 'airplane': ['heavier-than-air_craft', 'flight', 'jetliner', 'jet', 'Cessna'],\n",
       " 'uncle': ['son', 'brother', 'cousin', 'nephew', 'grandfather']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mws = ['cake', 'airplane', 'uncle'] # ...\n",
    "dict_of_cards = gen_many_cards(mws, category_prob_dist, model)\n",
    "dict_of_cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what do we ask?\n",
    "\n",
    "possibilities:\n",
    "- give the five taboo words, present three candidate main words, make them guess which one fits best?\n",
    "- give five taboo words, make participants think of the MW and rate their certainty that they've guessed what it probably is, and then show them the MW and make them answer yes/no whether they guessed it or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
