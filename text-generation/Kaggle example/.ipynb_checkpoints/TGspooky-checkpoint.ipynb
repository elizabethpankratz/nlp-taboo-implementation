{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# First try at text generation using Spooky data Kaggle competition\n",
    "Followed code from https://www.kaggle.com/ab971631/beginners-guide-to-text-generation-pytorch\n",
    "\n",
    "Main goals:\n",
    "* understanding pytorch\n",
    "* understanding text-generation approach\n",
    "* checking that machine and python3 conda session can run this kind of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "path = sys.path\n",
    "s = os.getcwd().rsplit(\"/\")[0:-2]\n",
    "sep = \"/\"\n",
    "f = sep.join(s)\n",
    "path.append(f)\n",
    "import taboo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/rlpa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU; consider making n_epochs very small.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
    "\n",
    "my_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This process, however, afforded me no means of...\n",
       "2    In his left hand was a gold snuff box, from wh...\n",
       "6    The astronomer, perhaps, at this point, took r...\n",
       "7          The surcingle hung in ribands from my body.\n",
       "8    I knew that you could not say to yourself 'ste...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "author = train_df[train_df['author'] == 'EAP'][\"text\"]\n",
    "author[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2802"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list(author[:100])\n",
    "def joinStrings(text):\n",
    "    return ' '.join(string for string in text)\n",
    "text = joinStrings(text)\n",
    "# text = [item for sublist in author[:5].values for item in sublist]\n",
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "        stop_free = \" \".join([i for i in doc.split() if i not in stop])\n",
    "        punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "        return normalized\n",
    "test_sentence = clean(text).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['this', 'process'], 'however'), (['process', 'however'], 'afforded'), (['however', 'afforded'], 'mean')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "chunk_len=len(trigrams)\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "voc_len=len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inp=[]\n",
    "tar=[]\n",
    "for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        inp.append(context_idxs)\n",
    "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        tar.append(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 10s (10 2%) 3.7190]\n",
      "[0m 21s (20 5%) 0.4474]\n",
      "[0m 32s (30 7%) 0.0351]\n",
      "[0m 43s (40 10%) 0.0098]\n",
      "[0m 54s (50 12%) 0.0051]\n",
      "[1m 5s (60 15%) 0.0036]\n",
      "[1m 16s (70 17%) 0.0030]\n",
      "[1m 27s (80 20%) 0.0026]\n",
      "[1m 38s (90 22%) 0.0024]\n",
      "[1m 49s (100 25%) 0.0022]\n",
      "[2m 0s (110 27%) 0.0020]\n",
      "[2m 11s (120 30%) 0.0019]\n",
      "[2m 21s (130 32%) 0.0018]\n",
      "[2m 32s (140 35%) 0.0017]\n",
      "[2m 43s (150 37%) 0.0016]\n",
      "[2m 54s (160 40%) 0.0015]\n",
      "[3m 5s (170 42%) 0.0014]\n",
      "[3m 16s (180 45%) 0.0013]\n",
      "[3m 27s (190 47%) 0.0013]\n",
      "[3m 37s (200 50%) 0.0012]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "print_every = 10\n",
    "plot_every = 10\n",
    "hidden_size = 50\n",
    "n_layers = 1\n",
    "lr = 0.015\n",
    "\n",
    "decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "if(train_on_gpu):\n",
    "    decoder.cuda()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(inp,tar)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 50, loss))\n",
    "#         print(evaluate('ge', 200), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a28a90b90>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str='this process', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long)\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is however great underduk suffered impertinence part little old man pas impunity i need tell sceptical i hitherto topic soul immortality presently murmur water fell gently upon ear moment afterward i turned road somewhat abruptly hitherto i became aware building kind\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('it is', 40, temperature = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
